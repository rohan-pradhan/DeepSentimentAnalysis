{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Using Deep Learning\n",
    "\n",
    "This notebook traines a convolutional neural network to recognize sentiments in a sentence. The data used here is the IMDB large movie review dataset freely available online.\n",
    "\n",
    "#### Loading raw data\n",
    "\n",
    "First step is to load the IMDB data into RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Using keras to load the dataset with the top_words\n",
    "top_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequence to the same length\n",
    "max_review_length = 1600\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "# Using embedding from Keras\n",
    "embedding_vecor_length = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "\n",
    "# Convolutional model (3x conv, flatten, 2x dense)\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "#model.add(Convolution1D(32, 3, padding='same'))\n",
    "#model.add(Convolution1D(16, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(180,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Log to tensorboard\n",
    "tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 412s 16ms/step - loss: 0.7251 - acc: 0.5146\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 457s 18ms/step - loss: 0.5567 - acc: 0.6647\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 499s 20ms/step - loss: 0.2399 - acc: 0.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fb87fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, callbacks=[tensorBoardCallback], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-21af594a1958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'If you like adult comedy cartoons, like South Park, then this is nearly a similar format about the small adventures of three teenage girls at Bromwell High. Keisha, Natella and Latrina have given exploding sweets and behaved like bitches, I think Keisha is a good leader. There are also small stories going on with the teachers of the school. Theres the idiotic principal, Mr. Bip, the nervous Maths teacher and many others. The cast is also fantastic, Lenny Henrys Gina Yashere, EastEnders Chrissie Watts, Tracy-Ann Oberman, Smack The Ponys Doon Mackichan, Dead Ringers Mark Perry and Blunders Nina Conti. I didnt know this came from Canada, but it is very good. Very good!'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 0 is positive, 1 is negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_words' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "X = [one_hot('If you like adult comedy cartoons, like South Park, then this is nearly a similar format about the small adventures of three teenage girls at Bromwell High. Keisha, Natella and Latrina have given exploding sweets and behaved like bitches, I think Keisha is a good leader. There are also small stories going on with the teachers of the school. Theres the idiotic principal, Mr. Bip, the nervous Maths teacher and many others. The cast is also fantastic, Lenny Henrys Gina Yashere, EastEnders Chrissie Watts, Tracy-Ann Oberman, Smack The Ponys Doon Mackichan, Dead Ringers Mark Perry and Blunders Nina Conti. I didnt know this came from Canada, but it is very good. Very good!',top_words)]\n",
    "\n",
    "# 0 is positive, 1 is negative\n",
    "X = sequence.pad_sequences(X, maxlen=max_review_length)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter dataset\n",
    "\n",
    "This section trains a deep neural network on the annotated twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32578</th>\n",
       "      <td>0</td>\n",
       "      <td>815449868739211264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>6847</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @DonaldJTrumpJr: Happy new year everyone. #...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32579</th>\n",
       "      <td>0</td>\n",
       "      <td>815433444591304704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>6941</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @EricTrump: 2016 was such an incredible yea...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32580</th>\n",
       "      <td>0</td>\n",
       "      <td>815433217595547648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>7144</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @Reince: Happy New Year + God's blessings t...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32581</th>\n",
       "      <td>0</td>\n",
       "      <td>815432169464197120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>5548</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @DanScavino: On behalf of our next #POTUS &amp;...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32582</th>\n",
       "      <td>126230</td>\n",
       "      <td>815422340540547072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>32665</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>TO ALL AMERICANS-\\n#HappyNewYear &amp;amp; many bl...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count              id_str  in_reply_to_user_id_str  \\\n",
       "32578               0  815449868739211264                      NaN   \n",
       "32579               0  815433444591304704                      NaN   \n",
       "32580               0  815433217595547648                      NaN   \n",
       "32581               0  815432169464197120                      NaN   \n",
       "32582          126230  815422340540547072                      NaN   \n",
       "\n",
       "       is_retweet  retweet_count              source  \\\n",
       "32578        True           6847  Twitter for iPhone   \n",
       "32579        True           6941  Twitter for iPhone   \n",
       "32580        True           7144  Twitter for iPhone   \n",
       "32581        True           5548  Twitter for iPhone   \n",
       "32582       False          32665  Twitter for iPhone   \n",
       "\n",
       "                                                    text Sentiment  \n",
       "32578  RT @DonaldJTrumpJr: Happy new year everyone. #...         P  \n",
       "32579  RT @EricTrump: 2016 was such an incredible yea...         P  \n",
       "32580  RT @Reince: Happy New Year + God's blessings t...         P  \n",
       "32581  RT @DanScavino: On behalf of our next #POTUS &...         P  \n",
       "32582  TO ALL AMERICANS-\\n#HappyNewYear &amp; many bl...         P  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "annotated = pd.read_csv('./annotated/bootstrapped.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "annotated.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32583 annotated rows\n"
     ]
    }
   ],
   "source": [
    "print(\"%i annotated rows\" % len(annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42547 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(documents['text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27252 to train\n",
      "49 max len\n"
     ]
    }
   ],
   "source": [
    "\n",
    "documents = annotated[1000:][['text', 'Sentiment']]\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "max_len = 0\n",
    "\n",
    "for doc in documents.itertuples():\n",
    "    if doc.Sentiment == 'Z':\n",
    "        continue\n",
    "    \n",
    "    hot = tokenizer.texts_to_sequences([doc.text])[0]\n",
    "    X_train.append(hot)\n",
    "    max_len = len(hot) if len(hot) > max_len else max_len\n",
    "    Y_train.append(1 if doc.Sentiment == 'P' else 0)\n",
    "\n",
    "print(\"%i to train\" % len(X_train))\n",
    "print('%i max len' % max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27252 data X_train\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "\n",
    "print('%i data X_train' % len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Convolution1D, Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "model = Sequential()\n",
    "embedding_vecor_length = 300\n",
    "model.add(Embedding(len(word_index) + 1, embedding_vecor_length, input_length=max_len))\n",
    "\n",
    "# Convolutional model (3x conv, flatten, 2x dense)\n",
    "model.add(Convolution1D(64, 3, padding='same'))\n",
    "model.add(Convolution1D(32, 3, padding='same'))\n",
    "model.add(Convolution1D(16, 3, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(180,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "27252/27252 [==============================] - 121s 4ms/step - loss: 0.2910 - acc: 0.8696\n",
      "Epoch 2/3\n",
      "27252/27252 [==============================] - 85s 3ms/step - loss: 0.2162 - acc: 0.9077\n",
      "Epoch 3/3\n",
      "27252/27252 [==============================] - 84s 3ms/step - loss: 0.1949 - acc: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1201740b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=3, callbacks=[tensorBoardCallback], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = annotated[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_tr_data.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_tr_data.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('tokenizer_cnn_tr.pickle', 'wb')\n",
    "pickle.dump(tokenizer, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
